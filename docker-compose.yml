# !!!!!!!!! NOTE !!!!!!!!!!!
# pass-through variables from environment into containers with ${VAR}
# start services with ./start.sh script
---
version: '2'
services:
  connect-ui:
    # docs: https://github.com/lensesio/kafka-connect-ui
    image: landoop/kafka-connect-ui
    ports:
    - 8007:8000
    environment:
      CONNECT_URL: http://connect:8083
    depends_on:
      - connect
  connect:
    image: confluentinc/cp-kafka-connect:5.4.1
    hostname: connect
    container_name: connect
    ports:
      - "8083:8083"
    volumes:
      - ./kafka_connect:/app
    command: /app/start.sh
    environment:
      # settings taken mostly from: https://docs.confluent.io/4.0.0/cloud/connect/connect-cloud-config.html#standalone-cluster
      CONNECT_BOOTSTRAP_SERVERS: ${BROKER_URL}

      CONNECT_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: https
      CONNECT_SASL_MECHANISM: PLAIN
      CONNECT_REQUEST_TIMEOUT_MS: 10000
      CONNECT_RETRY_BACKOFF_MS: 500
      CONNECT_SASL_JAAS_CONFIG: org.apache.kafka.common.security.plain.PlainLoginModule required username="${BROKER_KEY}" password="${BROKER_SECRET}" serviceName="kafka";
      CONNECT_SECURITY_PROTOCOL: SASL_SSL

      CONNECT_CONSUMER_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: https
      CONNECT_CONSUMER_SASL_MECHANISM: PLAIN
      CONNECT_CONSUMER_REQUEST_TIMEOUT_MS: 10000
      CONNECT_CONSUMER_RETRY_BACKOFF_MS: 500
      CONNECT_CONSUMER_SASL_JAAS_CONFIG: org.apache.kafka.common.security.plain.PlainLoginModule required username="${BROKER_KEY}" password="${BROKER_SECRET}" serviceName="kafka";
      CONNECT_CONSUMER_SECURITY_PROTOCOL: SASL_SSL

      CONNECT_PRODUCER_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: https
      CONNECT_PRODUCER_SASL_MECHANISM: PLAIN
      CONNECT_PRODUCER_REQUEST_TIMEOUT_MS: 10000
      CONNECT_PRODUCER_RETRY_BACKOFF_MS: 500
      CONNECT_PRODUCER_SASL_JAAS_CONFIG: org.apache.kafka.common.security.plain.PlainLoginModule required username="${BROKER_KEY}" password="${BROKER_SECRET}" serviceName="kafka";
      CONNECT_PRODUCER_SECURITY_PROTOCOL: SASL_SSL

      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 3
      CONNECT_CONFIG_STORAGE_TOPIC: docker_kafka_connect_config
      CONNECT_OFFSET_STORAGE_TOPIC: docker_kafka_connect_offset
      CONNECT_STATUS_STORAGE_TOPIC: docker_kafka_connect_status
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      # CLASSPATH required due to CC-2422
      CLASSPATH: /usr/share/java/monitoring-interceptors/monitoring-interceptors-5.4.1.jar
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_REST_ADVERTISED_HOST_NAME: connect

      SCHEMA_REGISTRY_ENDPOINT: ${SCHEMA_REGISTRY_ENDPOINT}
      SCHEMA_REGISTRY_KEY: ${SCHEMA_REGISTRY_KEY}
      SCHEMA_REGISTRY_SECRET: ${SCHEMA_REGISTRY_SECRET}

      KALEIDO_SUBMIT_TOPIC: ${KALEIDO_SUBMIT_TOPIC}
      KALEIDO_RECEIVE_TOPIC: ${KALEIDO_RECEIVE_TOPIC}
  kafka_faker:
    build: ./kafka_faker
    entrypoint: |
      bash -c "
      tail -f /dev/null"
    volumes:
      - ./kafka_faker:/app
    ports:
      - 6066:6066
    environment:
      WORKER_PORT: 6066
      KAFKA_BOOTSTRAP_SERVER: ${BROKER_URL}
      BROKER_KEY: ${BROKER_KEY}
      BROKER_SECRET: ${BROKER_SECRET}
      SSL_ENABLED: 1

      KALEIDO_SUBMIT_TOPIC: ${KALEIDO_SUBMIT_TOPIC}
      KALEIDO_RECEIVE_TOPIC: ${KALEIDO_RECEIVE_TOPIC}

      SCHEMA_REGISTRY_ENDPOINT: ${SCHEMA_REGISTRY_ENDPOINT}
      SCHEMA_REGISTRY_KEY: ${SCHEMA_REGISTRY_KEY}
      SCHEMA_REGISTRY_SECRET: ${SCHEMA_REGISTRY_SECRET}
  kafka_processors:
    build: ./kafka_processors
    entrypoint: |
      bash -c "
      tail -f /dev/null"
    volumes:
      - ./kafka_processors:/app
    ports:
      - 6067:6066
    environment:
      WORKER_PORT: 6066
      KAFKA_BOOTSTRAP_SERVER: ${BROKER_URL}
      BROKER_KEY: ${BROKER_KEY}
      BROKER_SECRET: ${BROKER_SECRET}
      SSL_ENABLED: 1

      KALEIDO_SUBMIT_TOPIC: ${KALEIDO_SUBMIT_TOPIC}
      KALEIDO_RECEIVE_TOPIC: ${KALEIDO_RECEIVE_TOPIC}

      SCHEMA_REGISTRY_ENDPOINT: ${SCHEMA_REGISTRY_ENDPOINT}
      SCHEMA_REGISTRY_KEY: ${SCHEMA_REGISTRY_KEY}
      SCHEMA_REGISTRY_SECRET: ${SCHEMA_REGISTRY_SECRET}
  db:
    image: postgres
    ports:
      - "8032:5432"
    environment:
      POSTGRES_PASSWORD: open
  eth_gateway_submit:
    build: ./eth_gateway
#    entrypoint: |
#      bash -c "
#      tail -f /dev/null"
#    volumes:
#      - ./eth_gateway/configs:/etc/kafka-mirrormaker
    environment:
      # [2020-09-29 11:21:12,736] ERROR Error when sending message to topic e0zgfop4ib-e0b4hhlppa-requests with key: null, value: 531 bytes with error: (org.apache.kafka.clients.producer.internals.ErrorLoggingCallback)
      #org.apache.kafka.common.errors.TimeoutException: Expiring 30 record(s) for e0zgfop4ib-e0b4hhlppa-requests-0: 260985 ms has passed since last append
      # то ли он не пытается отправить батч, то ли не может отправить и отваливается с таймаутом

      MIRRORMAKER_WHITE_LIST: ${KALEIDO_SUBMIT_TOPIC}
      MIRRORMAKER_ABORT_ON_SEND_FAILURE: "true"
      MIRRORMAKER_OFFSET_COMMIT_INTERVAL: 10000
      MIRRORMAKER_NUM_STREAMS: 1
#      MIRRORMAKER_CONSUMER_REBALANCE_LISTENER: org.mypackage.MyListener
#      MIRRORMAKER_CONSUMER_REBALANCE_LISTENER_ARGS: arg1,arg2
#      MIRRORMAKER_MESSAGE_HANDLER: org.mypackage.MyHandler
#      MIRRORMAKER_MESSAGE_HANDLER_ARGS: arg1,arg2

      CONSUMER_BOOTSTRAP_SERVERS: ${BROKER_URL}
      CONSUMER_GROUP_ID: MirrorMaker
      CONSUMER_AUTO_OFFSET_RESET: latest
      CONSUMER_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: https
      CONSUMER_SASL_MECHANISM: PLAIN
      CONSUMER_REQUEST_TIMEOUT_MS: 20000
      CONSUMER_RETRY_BACKOFF_MS: 500
      CONSUMER_SASL_JAAS_CONFIG: org.apache.kafka.common.security.plain.PlainLoginModule required username="${BROKER_KEY}" password="${BROKER_SECRET}" serviceName="kafka";
      CONSUMER_SECURITY_PROTOCOL: SASL_SSL

      PRODUCER_BOOTSTRAP_SERVERS: ${KALEIDO_BROKER_URLS}
      PRODUCER_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: https
      PRODUCER_SASL_MECHANISM: PLAIN
      PRODUCER_REQUEST_TIMEOUT_MS: 10000
      PRODUCER_RETRY_BACKOFF_MS: 500
      PRODUCER_SASL_JAAS_CONFIG: org.apache.kafka.common.security.plain.PlainLoginModule required username="${KALEIDO_BROKER_KEY}" password="${KALEIDO_BROKER_SECRET}" serviceName="kafka";
      PRODUCER_SECURITY_PROTOCOL: SASL_SSL

#      KALEIDO_SUBMIT_TOPIC: ${KALEIDO_SUBMIT_TOPIC}
  eth_gateway_receive:
    build: ./eth_gateway
    #    entrypoint: |
    #      bash -c "
    #      tail -f /dev/null"
    #    volumes:
    #      - ./eth_gateway/configs:/etc/kafka-mirrormaker
    environment:
      MIRRORMAKER_WHITE_LIST: ${KALEIDO_RECEIVE_TOPIC}
      MIRRORMAKER_ABORT_ON_SEND_FAILURE: "true"
      MIRRORMAKER_OFFSET_COMMIT_INTERVAL: 60000
      MIRRORMAKER_NUM_STREAMS: 1
#      MIRRORMAKER_CONSUMER_REBALANCE_LISTENER: org.mypackage.MyListener
#      MIRRORMAKER_CONSUMER_REBALANCE_LISTENER_ARGS: arg1,arg2
#      MIRRORMAKER_MESSAGE_HANDLER: org.mypackage.MyHandler
#      MIRRORMAKER_MESSAGE_HANDLER_ARGS: arg1,arg2

      CONSUMER_BOOTSTRAP_SERVERS: ${KALEIDO_BROKER_URLS}
      CONSUMER_GROUP_ID: MirrorMaker
      CONSUMER_AUTO_OFFSET_RESET: latest
      CONSUMER_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: https
      CONSUMER_SASL_MECHANISM: PLAIN
      CONSUMER_REQUEST_TIMEOUT_MS: 20000
      CONSUMER_RETRY_BACKOFF_MS: 500
      CONSUMER_SASL_JAAS_CONFIG: org.apache.kafka.common.security.plain.PlainLoginModule required username="${KALEIDO_BROKER_KEY}" password="${KALEIDO_BROKER_SECRET}" serviceName="kafka";
      CONSUMER_SECURITY_PROTOCOL: SASL_SSL

      PRODUCER_BOOTSTRAP_SERVERS: ${BROKER_URL}
      PRODUCER_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: https
      PRODUCER_SASL_MECHANISM: PLAIN
      PRODUCER_REQUEST_TIMEOUT_MS: 10000
      PRODUCER_RETRY_BACKOFF_MS: 500
      PRODUCER_SASL_JAAS_CONFIG: org.apache.kafka.common.security.plain.PlainLoginModule required username="${BROKER_KEY}" password="${BROKER_SECRET}" serviceName="kafka";
      PRODUCER_SECURITY_PROTOCOL: SASL_SSL
