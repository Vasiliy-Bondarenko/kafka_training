# !!!!!!!!! NOTE !!!!!!!!!!!
# pass-through variables from environment into containers with ${VAR}
# start services with ./start.sh script
---
version: '2'
services:
  connect-ui:
    # docs: https://github.com/lensesio/kafka-connect-ui
    image: landoop/kafka-connect-ui
    ports:
    - 8007:8000
    environment:
      CONNECT_URL: http://connect:8083
    depends_on:
      - connect
  connect:
    image: confluentinc/cp-kafka-connect:5.4.1
    hostname: connect
    container_name: connect
    ports:
      - "8083:8083"
    volumes:
      - ./kafka_connect:/app
    command: /app/start.sh
    environment:
      # settings taken mostly from: https://docs.confluent.io/4.0.0/cloud/connect/connect-cloud-config.html#standalone-cluster
      CONNECT_BOOTSTRAP_SERVERS: ${BROKER_URL}

      CONNECT_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: https
      CONNECT_SASL_MECHANISM: PLAIN
      CONNECT_REQUEST_TIMEOUT_MS: 10000
      CONNECT_RETRY_BACKOFF_MS: 500
      CONNECT_SASL_JAAS_CONFIG: org.apache.kafka.common.security.plain.PlainLoginModule required username="${BROKER_KEY}" password="${BROKER_SECRET}" serviceName="kafka";
      CONNECT_SECURITY_PROTOCOL: SASL_SSL

      CONNECT_CONSUMER_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: https
      CONNECT_CONSUMER_SASL_MECHANISM: PLAIN
      CONNECT_CONSUMER_REQUEST_TIMEOUT_MS: 10000
      CONNECT_CONSUMER_RETRY_BACKOFF_MS: 500
      CONNECT_CONSUMER_SASL_JAAS_CONFIG: org.apache.kafka.common.security.plain.PlainLoginModule required username="${BROKER_KEY}" password="${BROKER_SECRET}" serviceName="kafka";
      CONNECT_CONSUMER_SECURITY_PROTOCOL: SASL_SSL

      CONNECT_PRODUCER_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: https
      CONNECT_PRODUCER_SASL_MECHANISM: PLAIN
      CONNECT_PRODUCER_REQUEST_TIMEOUT_MS: 10000
      CONNECT_PRODUCER_RETRY_BACKOFF_MS: 500
      CONNECT_PRODUCER_SASL_JAAS_CONFIG: org.apache.kafka.common.security.plain.PlainLoginModule required username="${BROKER_KEY}" password="${BROKER_SECRET}" serviceName="kafka";
      CONNECT_PRODUCER_SECURITY_PROTOCOL: SASL_SSL

      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 3
      CONNECT_CONFIG_STORAGE_TOPIC: docker_kafka_connect_config
      CONNECT_OFFSET_STORAGE_TOPIC: docker_kafka_connect_offset
      CONNECT_STATUS_STORAGE_TOPIC: docker_kafka_connect_status
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      # CLASSPATH required due to CC-2422
      CLASSPATH: /usr/share/java/monitoring-interceptors/monitoring-interceptors-5.4.1.jar
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_REST_ADVERTISED_HOST_NAME: connect

      SCHEMA_REGISTRY_ENDPOINT: ${SCHEMA_REGISTRY_ENDPOINT}
      SCHEMA_REGISTRY_KEY: ${SCHEMA_REGISTRY_KEY}
      SCHEMA_REGISTRY_SECRET: ${SCHEMA_REGISTRY_SECRET}
  kafka_faker:
    build: ./kafka_faker
    entrypoint: |
      bash -c "
      tail -f /dev/null"
    volumes:
      - ./kafka_faker:/app
    ports:
      - 6066:6066
    environment:
      WORKER_PORT: 6066
      KAFKA_BOOTSTRAP_SERVER: ${BROKER_URL}
      BROKER_KEY: ${BROKER_KEY}
      BROKER_SECRET: ${BROKER_SECRET}
      SSL_ENABLED: 1

      SCHEMA_REGISTRY_ENDPOINT: ${SCHEMA_REGISTRY_ENDPOINT}
      SCHEMA_REGISTRY_KEY: ${SCHEMA_REGISTRY_KEY}
      SCHEMA_REGISTRY_SECRET: ${SCHEMA_REGISTRY_SECRET}
#  app:
#    build: .
#    entrypoint: |
#      bash -c "
#      tail -f /dev/null"
#    volumes:
#      - .:/app
  db:
    image: postgres
    ports:
      - "8032:5432"
    environment:
      POSTGRES_PASSWORD: open
